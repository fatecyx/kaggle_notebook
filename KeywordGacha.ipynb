{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KeywordGacha_NV_v0.5.0\n",
    "\n",
    "- **作者**: [https://github.com/neavo/KeywordGacha](https://github.com/neavo/KeywordGacha)\n",
    "\n",
    "## 使用方法\n",
    "\n",
    "* 导入models:\n",
    "从 `fatecyx/my_model` 中导入 `llama-box` 和 `glm-4-9b-chat-q4_k_s` 模型。\n",
    "\n",
    "* 导入datasets\n",
    "导入 `fatecyx/KeywordGacha2` 数据集。\n",
    "\n",
    "* 导入输入数据\n",
    "根据实际目录修改命令中的`/kaggle/input/gt-input/gt_input`:\n",
    "\n",
    "```bash\n",
    "!cp -r /kaggle/input/gt-input/gt_input /kaggle/working/KeywordGacha/input\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/my_model/gguf/llama-box/1/llama-box /kaggle/working/llama-box\n",
    "!chmod a+x /kaggle/working/llama-box\n",
    "!cp -r /kaggle/input/keywordgacha2/KeywordGacha /kaggle/working/KeywordGacha\n",
    "!cp -r /kaggle/input/gt-input/gt_input /kaggle/working/KeywordGacha/input\n",
    "%cd /kaggle/working/KeywordGacha\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def local_model(dic_status):\n",
    "    cmd = \"/kaggle/working/llama-box -c 8192 -np 4 -ngl 999 --host 0.0.0.0 -m /kaggle/input/my_model/gguf/glm-4-9b-chat-q4_k_s/1/glm-4-9b-chat-Q4_K_S.gguf\"\n",
    "    \n",
    "    \n",
    "    p = subprocess.Popen(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)\n",
    "    for line in p.stderr:\n",
    "        if not dic_status['status']:\n",
    "            s2 = line.decode()\n",
    "            dic_status['msg'] = s2\n",
    "            if \"main: starting server\" in s2:\n",
    "                dic_status['status'] = True\n",
    "            if \"main: exiting due to model loading error\" in s2:\n",
    "                print(\"启动失败\")\n",
    "        \n",
    "        #print(line.decode(), end='')\n",
    "dic_status = {'status': False, 'msg': ''}\n",
    "\n",
    "threading.Thread(target=local_model, daemon=True, args=(dic_status,)).start()\n",
    "\n",
    "s = \"\"\n",
    "while not dic_status['status']:\n",
    "    if s != dic_status['msg']:\n",
    "        s = dic_status['msg']\n",
    "        print(s)\n",
    "print(\"模型启动成功\")\n",
    "\n",
    "\n",
    "#!./llama-box -c 8192 -np 4 --host 0.0.0.0 -m /kaggle/input/my_model/gguf/glm-4-9b-chat-q4_k_s/1/glm-4-9b-chat-Q4_K_S.gguf\n",
    "!curl http://localhost:8080/v1/completions -H \"Content-Type: application/json\" -d '{\"model\": \"glm4\", \"stream\" : false,\"temperature\" : 0.05, \"top_p\" : 0.85,\"max_tokens\" : 768, \"frequency_penalty\" : 0,\"prompt\": \"<|system|>You are a helpful assistant.<|user|你好<|assistant|>\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/working/KeywordGacha\n",
    "with open(\"input.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(\"3\\n1\\n/kaggle/working/KeywordGacha/input\\n\")\n",
    "!python /kaggle/working/KeywordGacha/main.py < input.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l /kaggle/working/KeywordGacha/output\n",
    "\n",
    "import shutil\n",
    "shutil.make_archive('/kaggle/working/result', 'zip', '/kaggle/working/KeywordGacha/output')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
